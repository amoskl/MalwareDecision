__author__ = 'Yishai'

# import informationgain

# The basic nodes the decision tree is made of. Since we only check whether specific n-ngrams are present or
# missing, the nodes are always binary. Each 'leaf' node must have TerminalNode objects as its children.
class Node:
    def __init__(self, ngram, child_ngram_present=None, child_ngram_missing=None):
        self.ngram = ngram
        self.child_with_ngram = child_ngram_present
        self.child_without_ngram = child_ngram_missing

    def isTerminal(self):
        return False

    def getChildWithNgram(self):
        return self.child_with_ngram

    def getChildWithoutNgram(self):
        return self.child_without_ngram

    def setChildWithNgram(self, child):
        self.child_with_ngram = child

    def setChildWithoutNgram(self, child):
        self.child_without_ngram = child

    def getNGram(self):
        return self.ngram

    def directToChild(self, ngram_list):
        for ngram in ngram_list:
            if ngram == self.ngram:
                return self.child_with_ngram

        return self.child_without_ngram

# The TerminalNode object represents the leaf nodes of the decision tree that each decision eventually reaches.
# They quite simply decide whether the path they appear in represents a Positive (malware) or a Negative (benign)
# sample.
class TerminalNode:
    def __init__(self, truth_value):
        self.truth_value = truth_value

    def getValue(self):
        return self.truth_value

    def isTerminal(self):
        return True

# The decision tree object is used to classify executable files into malicious and benign
# files. It checks for the presence of specific n-grams in the file and then, based on their
# presence, makes its decision.
# The decision tree is binary, as it checks the presence of n-grams.
class DecisionTree:

    # The decision tree should have a node for each n-gram present in the collection passed to it.
    # According to the Kolter and Maloof paper, this size should be approximately 500.
    # The best decision trees will most likely be made using the best n-grams, so it is useful
    # to filter the n-gram collection appropriately before passing it to the constructor.
    def __init__(self, ngram_collection):
        self.ngram_pool = ngram_collection

        from random import choice # placeholder code
        self.root = choice(ngram_collection)
        # TODO: decision tree constructs and arranges its structure using the information gain formula

        # TODO: sanity check -- iterate on every non-terminal node in the tree and make sure it has TerminalNode children.
        # potentially, might also want to include a test that no node has two terminal children with the same truth
        # value. It is theoretically feasible, since the number of nodes in the tree is constant, but extremely
        # unlikely that we would encounter nodes with information gain 0 for trees that only have a few hundred nodes.



    # classify the given input_ngram by descending down the decision tree until a terminal node containing the
    # truth value corresponding to the decision is encountered.
    def classify(self, input_ngram):
        current_node = self.root
        while not current_node.isTerminal():
            current_node = current_node.directToChild(input_ngram)

        return current_node.getValue()